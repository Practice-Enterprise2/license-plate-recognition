{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvcc: command not found\n",
      "torch:  2.0 ; cuda:  2.0.0.post200\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile as zf\n",
    "\n",
    "with zf('a.zip','r') as zin:\n",
    "    zin.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('images/Cars0.png')  # Replace 'image.jpg' with the path to your image file\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Image', im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2], device='cuda:0')\n",
      "Boxes(tensor([[  0.0000,   0.0000, 457.9788, 248.4266]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
    "print(outputs[\"instances\"].pred_classes)\n",
    "print(outputs[\"instances\"].pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Image',out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile as zf\n",
    "\n",
    "with zf('b.zip','r') as zin:\n",
    "    zin.extractall('./content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from cv2 import imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_dicts(img_dir):\n",
    "    \"\"\"This function loads the JSON file created with the annotator and converts it to\n",
    "    the detectron2 metadata specifications.\n",
    "    \"\"\"\n",
    "    # load the JSON file\n",
    "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
    "    with open(json_file) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    # loop through the entries in the JSON file\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "        # add file_name, image_id, height and width information to the records\n",
    "        filename = os.path.join(img_dir, v[\"filename\"])\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        annos = v[\"regions\"]\n",
    "\n",
    "        objs = []\n",
    "        # one image can have multiple annotations, therefore this loop is needed\n",
    "        for annotation in annos:\n",
    "            # reformat the polygon information to fit the specifications\n",
    "            anno = annotation[\"shape_attributes\"]\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            region_attributes = annotation[\"region_attributes\"][\"class\"]\n",
    "\n",
    "            # specify the category_id to match with the class.\n",
    "\n",
    "            if \"building\" in region_attributes:\n",
    "                category_id = 1\n",
    "            elif \"window\" in region_attributes:\n",
    "                category_id = 0\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": category_id,\n",
    "                \"iscrowd\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "\n",
    "    return dataset_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'buildings_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/maestro/ANPR/license-plate-recognition/.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# the data has to be registered within detectron2, once for the train and once for\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# the val data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     DatasetCatalog\u001b[39m.\u001b[39;49mregister(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mbuildings_\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m d,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mlambda\u001b[39;49;00m d\u001b[39m=\u001b[39;49md: get_building_dicts(\u001b[39m\"\u001b[39;49m\u001b[39m./content/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m d),\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m building_metadata \u001b[39m=\u001b[39m MetadataCatalog\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbuildings_train\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/maestro/ANPR/license-plate-recognition/.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m dataset_dicts \u001b[39m=\u001b[39m get_building_dicts(\u001b[39m\"\u001b[39m\u001b[39m./content/train\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/t/lib/python3.8/site-packages/detectron2/data/catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mcallable\u001b[39m(func), \u001b[39m\"\u001b[39m\u001b[39mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[39massert\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is already registered!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name)\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m[name] \u001b[39m=\u001b[39m func\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'buildings_train' is already registered!"
     ]
    }
   ],
   "source": [
    "# the data has to be registered within detectron2, once for the train and once for\n",
    "# the val data\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\n",
    "        \"buildings_\" + d,\n",
    "        lambda d=d: get_building_dicts(\"./content/\" + d),\n",
    "    )\n",
    "\n",
    "building_metadata = MetadataCatalog.get(\"buildings_train\")\n",
    "\n",
    "dataset_dicts = get_building_dicts(\"./content/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(random.sample(dataset_dicts, 2)):\n",
    "    # read the image with cv2\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=building_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "    imshow('Image',vis.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # if you want to save the files, uncomment the line below, but keep in mind that\n",
    "    # the folder inputs has to be created first\n",
    "    # plt.savefig(f\"./inputs/input_{i}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
